{"version":3,"sources":["meteor://ðŸ’»app/packages/ground_db/groundDB.client.js","meteor://ðŸ’»app/packages/ground_db/wrap.collection.js","meteor://ðŸ’»app/packages/ground_db/wrap.eventemitter.js","meteor://ðŸ’»app/packages/ground_db/wrap.proto.eventemitter.js"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4H;;;;;;;;;;;;;;;;;;AC1+BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0H;;;;;;;;;;;;;;;;;;ACtCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0H;;;;;;;;;;;;;;;;;;ACpCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0H","file":"/packages/ground_db.js","sourcesContent":["/*\n               ______                           ______  ____\n              / ____/________  __  ______  ____/ / __ \\/ __ )\n             / / __/ ___/ __ \\/ / / / __ \\/ __  / / / / __  |\n            / /_/ / /  / /_/ / /_/ / / / / /_/ / /_/ / /_/ /\n            \\____/_/   \\____/\\__,_/_/ /_/\\__,_/_____/_____/\n\n\nGroundDB is a thin layer providing Meteor offline database and methods\n\nConcept, localstorage is simple wide spread but slow\n\nGroundDB saves outstanding methods and minimongo into localstorage at window\nunload, but can be configured to save at any changes and at certain interval(ms)\n\nWhen the app loads GroundDB resumes methods and database changes\n\nRegz. RaiX\n\n*/\n\n/* global Ground: true */\n/* global GroundDB: true */       // This global is deprecating */\n/* global MiniMax: false */       // ground:minimax */\n/* global _groundUtil: false */   // ground:util */\n/* global OneTimeout: false */    // ground:util - use _.debounce instead */\n/* global Store: false */         // ground:store */\n/* global EventEmitter: false */  // raix:eventemitter */\n/* global Kernel: false */        // dispatch:kernel */\n\n///////////////////////////////// TEST BED /////////////////////////////////////\n\nvar test;\n\ntry {\n  test = Package['ground:test'].GroundTest;\n  console.warn('## IN TEST MODE');\n} catch(err) {\n  // Production noop\n  test = {\n    log: function() {},\n    debug: function() {},\n    isMain: false\n  };\n}\n\n//////////////////////////////// GROUND DATABASE ///////////////////////////////\n\n// XXX: This usage of minimax could be extended to letting the user add more\n// words to the dictionary - but its not without danger and should prop. trigger\n// some warning if no migration scheme is setup...\nvar MiniMaxDB = new MiniMax({\n  // We add the most general words in databases\n dictionary: ['_id', 'createdAt', 'createdBy', 'updatedAt', 'updatedBy']\n});\n\nvar MiniMaxMethods = new MiniMax({\n  // We add the most general words in databases\n  dictionary: ['method', 'args', 'options', 'wait', '_id']\n});\n\n// Status of app reload\nvar _isReloading = false;\n\n// Add a pointer register of grounded databases\nvar _groundDatabases = {};\n\nvar noop = function noop() {};\n\n// This function will add a emitter for the \"changed\" event\nvar _addChangedEmitter = function _addChangedEmitter() {\n  var self = this;\n  // Reactive deps for when data changes\n  var _dataChanged = new Tracker.Dependency();\n\n  var _changeData = function _changeData() { _dataChanged.changed(); };\n\n  Tracker.autorun(function _changeDataAutorun() {\n    // Depend on data change\n    _dataChanged.depend();\n    // Emit changed\n    self.collection.emit('changed');\n  });\n\n  // Observe all changes and rely on the less agressive observer system for\n  // providing a reasonable update frequens\n  self.collection.find().observe({\n    'added': _changeData,\n    'changed': _changeData,\n    'removed': _changeData\n  });\n};\n\n// Clean up the local data and align to the subscription\nvar _cleanUpLocalData = function _cleanUpLocalData() {\n  var self = this;\n  // Flag marking if the local data is cleaned up to match the subscription\n  self.isCleanedUp = false;\n\n  Tracker.autorun(function _cleanUpLocalDataAutorun(computation) {\n    if (Ground.ready() && !self.isCleanedUp) {\n      // If all subscriptions have updated the system then remove all local only\n      // data?\n      // console.log('Clean up ' + self.name);\n      self.isCleanedUp = true;\n      _removeLocalOnly.call(self);\n\n      // Stop this listener\n      computation.stop();\n    }\n  });\n};\n\n// Setup the syncronization of tabs\nvar _setupTabSyncronizer = function _setupTabSyncronizer() {\n  var self = this;\n  // We check to see if database sync is supported, if so we sync the database\n  // if data has changed in other tabs\n  if (typeof _syncDatabase === 'function') {\n\n    // Listen for data changes\n    self.storage.addListener('storage', function _setupTabSyncronizerListener() {\n\n      // Database changed in another tab - sync this db\n      _syncDatabase.call(self);\n\n    });\n\n  }\n};\n\n// Rig the change listener and make sure to store the data to local storage\nvar _setupDataStorageOnChange = function _setupDataStorageOnChange() {\n  var self = this;\n\n  // Add listener, is triggered on data change\n  self.collection.addListener('changed', function _setupDataStorageOnChangeListener() {\n\n    // Store the database in store when ever theres a change\n    // the _saveDatabase will throttle to optimize\n    _saveDatabase.call(self);\n\n  });\n};\n\n// This is the actual grounddb instance\nvar _groundDbConstructor = function _groundDbConstructor(collection, options) {\n  var self = this;\n\n  // Check if user used the \"new\" keyword\n  if (!(self instanceof _groundDbConstructor)) {\n    throw new Error('_groundDbConstructor expects the use of the \"new\" keyword');\n  }\n\n  self.collection = collection;\n\n  // Set Ground.Collection prefix for localstorage\n  var _prefix = options && options.prefix || '';\n\n  // Set helper to connection\n  self.connection = collection._connection;\n\n  // Set helper to minimongo collection\n  self._collection = collection._collection;\n\n  // Is this an offline client only database?\n  self.offlineDatabase = (self.connection === null);\n\n  // Initialize collection name\n  // XXX: Using null as a name is a problem - only one may be called null\n  self.name = (collection._name)? collection._name : 'null';\n\n  /////// Finally got a name... and rigged\n\n  // One timeout pointer for database saves\n  self._saveDatabaseTimeout = new OneTimeout(200);\n\n  // Rig resume for this collection\n  if (!self.offlineDatabase && options.resume !== false) {\n\n    Ground.methodResume([\n      '/' + self.name + '/insert',\n      '/' + self.name + '/remove',\n      '/' + self.name + '/update'\n    ], self.connection);\n\n  }\n\n  // Get the best storage available\n  self.storage = Store.create({\n    // We allow the user to set a prefix for the storage. Its mainly ment for\n    // testing purposes, since the prefixing allows the tests to simulate more\n    // complex scenarios\n    name: _prefix + self.name,\n    // Default version is 1.0 - if different from the one in storage record it\n    // would trigger a migration\n    version: options.version ||Â 1.1,\n    // migration can be set to overwrite the default behaviour on the storage.\n    // the options.migration should be a function(oldRecord, newRecord)\n    // one can compare the oldRecord.version and the new version to ensure\n    // correct migration steps.\n    // That said the default behaviour simply clears the storage.\n    migration: options.migration\n  });\n\n  // Rig an event handler on Meteor.Collection\n  collection.eventemitter = new EventEmitter();\n\n  // Add to pointer register\n  // XXX: should we throw an error if already found?\n  // Store.create will prop. throw an error before...\n  _groundDatabases[ self.name ] = self;\n\n  // We have to allow the minimongo collection to contain data before\n  // subscriptions are ready\n  _hackMeteorUpdate.call(self);\n\n  // Flag true/false depending if database is loaded from local\n  self._databaseLoaded = false;\n\n  // Map local-only - this makes sure that localstorage matches remote loaded db\n  self._localOnly = {};\n\n  // Clean up the database and align to subscription - we dont do this for\n  // pure offline databases\n  if (options.cleanupLocalData && !self.offlineDatabase) {\n    _cleanUpLocalData.call(self);\n  }\n\n  // Add api for Clean up local only data\n  // If passing query we'll remove only those that pass it (and of course are only local)\n  self.collection.removeLocalOnly = function removeLocalOnly(query) {\n    self.isCleanedUp = true;\n    _removeLocalOnly.call(self, query);\n  };\n\n  self.collection.clear = function clear(callback) {\n\n    if (typeof callback !== 'function') { callback = noop; }\n\n    // Clean storage\n    self.storage.clear(callback);\n\n    // Empty collection\n    self._collection.remove({});\n    // // Set empty map\n    // _groundUtil.setDatabaseMap(self, {});\n\n    // // Invalidate the database\n    // _groundUtil.invalidateDb(self);\n  };\n\n  // Add the emitter of \"changed\" events\n  _addChangedEmitter.call(self);\n\n  // The data changes should be stored in storage\n  _setupDataStorageOnChange.call(self);\n\n  // Load the database as soon as possible\n  _loadDatabase.call(self);\n\n  // Add tab syncronizer\n  _setupTabSyncronizer.call(self);\n\n};\n\n// Global helper for applying grounddb on a collection\nGround.Collection = function groundCollection(name, options) {\n  var self;\n\n  // Inheritance Meteor Collection can be set by options.collection\n  // Accepts smart collections by Arunoda Susiripala\n  // Check if user used the \"new\" keyword\n\n\n  // Make sure we got some options\n  options = _.extend({\n    // By default local data is cleaned up when all subscriptions are ready\n    // but thats not what we would do always\n    cleanupLocalData: true\n  }, options);\n\n  // Either name is a Meteor collection or we create a new Meteor collection\n  if (name instanceof _groundUtil.Collection) {\n    self = name;\n  } else {\n    self = new _groundUtil.Collection(name, options);\n  }\n\n  // Throw an error if something went wrong\n  if (!(self instanceof _groundUtil.Collection)) {\n    throw new Error('Ground.Collection expected a Mongo.Collection');\n  }\n\n  // Add grounddb to the collection, circular reference since self is\n  // grounddb.collection\n  self.grounddb = new _groundDbConstructor(self, options);\n\n  // Return grounded collection - We dont return this eg if it was an instance\n  // of Ground.Collection\n  return self;\n};\n\n////////////////////////////////////////////////////////////////////////////////\n// Private Methods\n////////////////////////////////////////////////////////////////////////////////\n\n/*\n\nTODO: Implement conflict resoultion\n\nThe _hackMeteorUpdate should be modified to resolve conflicts via default or\ncustom conflict handler.\n\nThe first thing we have to do is to solve the \"remove\" operation - Its quite\ntricky and there are a couple of patterns we could follow:\n\n1. Create a register for removed docs - but how long should we store this data?\n2. Stop the real remove, add a removedAt serverStamp in an empty doc instead\n3. Find a way to get a removedAt timestamp in another way\n\nSo we cant trust that having the data at the server makes everything ok,\n\n---\nThe scenario or question to answer is:\n\nclientA creates a document and goes offline\nclientB removes the document\nafter a day, a month or years?:\nclientA edits the document and goes online\n\nSo what should happen?\n---\n\nIf we want the newest change to win, then the document should be restored\n\nIf clientA and clientB is the same user we would assume they kinda know what\nthey are doing, but if you edit the docuemnt after you removed it - it seems\nlike an user error removing the document.\n\nBut now time comes into play, if it was 6 month ago the user removed the document,\nand now edits it offline then going online would still restore the document?\nThis raises the question of how long time should we store details about removed\ndocuments... and where?\n\nShould destructive actions be comprimised, rather dont remove?\n\nNow if the user updates a document - should we try to merge the data, sometimes\nyes, sometimes no.\n\nNever the less - this is an example of the power a custom conflict handler\nshould have. So the task is to provide the tooling and data for the conflict\nhandlers.\n\nA conflict handler is really a question about strategy, how the app should\nact in the situation. This is why we are going to have the client-side do this\nwork - I mean we could have a strategy for letting the user decide what should\nhappen.\n\nThe conflict handler should be provided the localVersion and remoteVersion,\nit should then return the winning result - might be in a callback allowing\nsync + async behaviours?\n\nSo this is focused on servertime stamps - but the interesting thing here could\nalso be the focus on versions instead. Much like OT and github does.\n\nBut OT will prop. only make sense when all online?\n\n---\n\nShould it be the server that handles conflicts? All the data is available there\nwe cant be sure about subscriptions + we could have OT records for each collection\nCreating a conflict resoultion package could be isolated and would work on all\ncollections - grounded or not...\n\nWe could wait until OT is supported in core?\n\n*/\nvar _hackMeteorUpdate = function _hackMeteorUpdate() {\n  var self = this;\n\n  // Super container\n  var _super;\n\n  // Overwrite the store update\n  if (self.connection && self.connection._stores[ self.name ]) {\n    // Set super\n    _super = self.connection._stores[ self.name ].update;\n    // Overwrite\n    self.connection._stores[ self.name ].update = function groundUpdate(msg) {\n      // console.log('GOT UPDATE');\n      var mongoId = msg.id && _groundUtil.idParse(msg.id);\n      var doc = msg.id && self._collection.findOne(mongoId);\n      // We check that local loaded docs are removed before remote sync\n      // otherwise it would throw an error\n        // When adding and doc allready found then we remove it\n      if (msg.msg === 'added' && doc) {\n          // We mark the data as remotely loaded TODO:\n          delete self._localOnly[mongoId];\n          // Solve the conflict - server wins\n          // Then remove the client document\n          self._collection.remove(mongoId);\n      }\n      // If message wants to remove the doc but allready removed locally then\n      // fix this before calling super\n      if (msg.msg === 'removed' && !doc) {\n        self._collection.insert({_id: mongoId});\n      }\n      // Call super and let it do its thing\n      _super(msg);\n    };\n  }\n};\n\n\n// We dont trust the localstorage so we make sure it doesn't contain\n// duplicated id's - primary a problem i FF\nvar _checkDocs = function _checkDocs(a) {\n  var c = {};\n  // // We create c as an object with no duplicate _id's\n  // for (var i = 0, keys = Object.keys(a); i < keys.length; i++) {\n  //   // Extract key/value\n  //   var key = keys[i];\n  //   var doc = a[key];\n  //   // set value in c\n  //   c[key] = doc;\n  // }\n\n  _groundUtil.each(a, function iterateDoc(doc, key) {\n    c[key] = doc;\n  });\n  return c;\n};\n\n// At some point we can do a remove all local-only data? Making sure that we\n// Only got the same data as the subscription\n// If passing query we'll remove only those that pass it (and of course are only local)\nvar _removeLocalOnly = function _removeLocalOnly(query) {\n  var self = this;\n  query = query || {};\n\n  _groundUtil.each(self._localOnly, function _loadDatabaseEach(isLocalOnly, id) {\n    if (isLocalOnly) {\n      self._collection.remove({ $and: [{ _id: id }, query] });\n      delete self._localOnly[id];\n    }\n  });\n};\n\n// Bulk Load database from local to memory\nvar _loadDatabase = function _loadDatabase() {\n  var self = this;\n  // Then load the docs into minimongo\n\n  // Emit event\n  self.collection.emit('resume', { type: 'database' });\n  Ground.emit('resume', { type: 'database', collection: self.name });\n\n  // Load object from localstorage\n  self.storage.getItem('data', function storageGetItem(err, data) {\n    if (!err) {\n\n      self.collection.emit('resumed', { type: 'database', data: data });\n      Ground.emit('resumed', { type: 'database', collection: self.name });\n\n      // Maxify the data\n      var docs = data && MiniMaxDB.maxify(data) || {};\n\n      // Initialize client documents\n      Kernel\n      .each(_checkDocs.call(self, docs || {} ), function kernelEach(doc) {\n        // Test if document allready exists, this is a rare case but accounts\n        // sometimes adds data to the users database, eg. if \"users\" are grounded\n        var exists = self._collection.findOne(doc._id);\n        // If collection is populated before we get started then the data in\n        // memory would be considered latest therefor we dont load from local\n        if (!exists) {\n          if (!self.offlineDatabase) {\n            // If online database then mark the doc as local only TODO:\n            self._localOnly[doc._id] = true;\n          }\n          self._collection.insert(doc);\n        }\n      })\n      .then(function afterKernelEach() {\n        // Setting database loaded, this allows minimongo to be saved into local\n        self._databaseLoaded = true;\n        self.collection.emit('loaded', { type: 'database', data: data });\n        Ground.emit('loaded', { type: 'database', collection: self.name });        \n      });\n\n    }\n\n  });\n};\n\n// Bulk Save database from memory to local, meant to be as slim, fast and\n// realiable as possible\nvar _saveDatabase = function _saveDatabase() {\n  var self = this;\n  // If data loaded from localstorage then its ok to save - otherwise we\n  // would override with less data\n  if (self._databaseLoaded && _isReloading === false) {\n    self._saveDatabaseTimeout(function _saveDatabaseTimeout() {\n      // We delay the operation a bit in case of multiple saves - this creates\n      // a minor lag in terms of localstorage updating but it limits the num\n      // of saves to the database\n      // Make sure our database is loaded\n      self.collection.emit('cache', { type: 'database' });\n      Ground.emit('cache', { type: 'database', collection: self.name });\n      var minifiedDb = MiniMaxDB.minify(_groundUtil.getDatabaseMap(self));\n      // Save the collection into localstorage\n      self.storage.setItem('data', minifiedDb, function storageCache(err) {\n        // Emit feedback\n        if (err) {\n          // Emit error\n          self.collection.emit('error', { error: err });\n          Ground.emit('error', { collection: self.name, error: err });\n        } else {\n          // Emit cached event\n          self.collection.emit('cached', { type: 'database', data: minifiedDb });\n          Ground.emit('cached', { type: 'database', collection: self.name });\n        }\n      });\n\n    });\n  }\n};\n\n\n// Reactive variable containing a boolean flag, true == all subscriptions have\n// been loaded\n// XXX: this should be a bit more finegrained eg. pr. collection, but thats not\n// possible yet\nGround.ready = _groundUtil.allSubscriptionsReady;\n\nGround.lookup = function groundLookup(collectionName) {\n  return _groundDatabases[collectionName];\n};\n\nvar _allowMethodResumeMap = {};\nvar _methodResumeConnections = [];\n\nvar addConnectionToResume = function addConnectionToResume(connection) {\n  if (_methodResumeConnections.indexOf(connection) < 0) {\n    _methodResumeConnections.push(connection);\n  }\n};\n\nGround.methodResume = function methodResume(names, connection) {\n  // Allow string or array of strings\n  if (names === ''+names) {\n    names = [names];\n  }\n\n  // Default to the default connection...\n  connection = connection || _groundUtil.connection;\n\n  // This index comes in handy when we use getMethodList\n  addConnectionToResume(connection);\n\n  // Add methods to resume\n  _groundUtil.each(names, function(name) {\n    _allowMethodResumeMap[name] = connection;\n  });\n  // console.log(_allowMethodResumeMap);\n};\n\n// Add settings for methods to skip or not when caching methods\nGround.skipMethods = function skipMethods() {\n  throw new Error('Ground.skipMethods is deprecated, use Ground.methodResume instead');\n};\n\nGround.OneTimeout = OneTimeout;\n\n///////////////////////////// RESUME METHODS ///////////////////////////////////\n\n// Is methods resumed?\nvar _methodsResumed = false;\nvar _methodsResumedDeps = new Tracker.Dependency();\n\n\nGround.isResumed = function isResumed() {\n  _methodsResumedDeps.depend();\n  return _methodsResumed;\n};\n\n// Get a nice array of current methods\nvar _getMethodsList = function _getMethodsList() {\n  // Array of outstanding methods\n  var methods = [];\n  // Made a public API to disallow caching of some method calls\n  // Convert the data into nice array\n\n  // We iterate over the connections that have resumable methods\n  _groundUtil.each(_methodResumeConnections, function resumeEachConnection(connection) {\n    // We run through the method invokers\n    _groundUtil.each(connection._methodInvokers, function resumeEachInvoker(method) {\n      // Get the method name\n      var name = method._message.method;\n      // Check that this method is resumeable and on the correct connection\n      if (_allowMethodResumeMap[name] === connection) {\n        // Push the method\n        methods.push({\n          // Format the data\n          method: name,\n          args: method._message.params,\n          options: { wait: method._wait }\n        });\n\n      }\n\n    });\n  });\n\n  return methods;\n};\n\n// Flush in memory methods, its a dirty trick and could have some edge cases\n// that would throw an error? Eg. if flushed in the middle of waiting for\n// a method call to return - the returning call would not be able to find the\n// method callback. This could happen if the user submits a change in one window\n// and then switches to another tab and submits a change there before the first\n// method gets back?\nvar _flushInMemoryMethods = function _flushInMemoryMethods() {\n  var didFlushSome = false;\n  // TODO: flush should be rewritten to - we should do method proxy stuff...\n  // This code is a bit dirty\n  if (_groundUtil.connection && _groundUtil.connection._outstandingMethodBlocks &&\n          _groundUtil.connection._outstandingMethodBlocks.length) {\n\n    // Clear the in memory outstanding methods TODO: Check if this is enough\n    // Check to see if we should skip methods\n    for (var i = 0; i < _groundUtil.connection._outstandingMethodBlocks.length; i++) {\n      var method = _groundUtil.connection._outstandingMethodBlocks[i];\n      if (method && method._message && _allowMethodResumeMap[method._message.method]) {\n        // Clear invoke callbacks\n//    _groundUtil.connection._outstandingMethodBlocks = [];\n        delete _groundUtil.connection._outstandingMethodBlocks[i];\n//    _groundUtil.connection._methodInvokers = {};\n        delete _groundUtil.connection._methodInvokers[i];\n        // Set the flag to call back\n        didFlushSome = true;\n      }\n    }\n    if (didFlushSome) {\n      // Call the event callback\n      Ground.emit('flush', { type: 'methods' });\n    }\n\n  }\n};\n\n// Extract only newly added methods from localstorage\nvar _getMethodUpdates = function _getMethodUpdates(newMethods) {\n  var result = [];\n  if (newMethods && newMethods.length > 0) {\n    // Get the old methods allready in memory\n    // We could have done an optimized slice version or just starting at\n    // oldMethods.length, but this tab is not in focus\n    var oldMethods = _getMethodsList();\n    // We do a check to see if we should flush our in memory methods if allready\n    // run on an other tab - an odd case - the first item would not match in\n    // old methods and new methods, its only valid to make this test if both\n    // methods arrays are not empty allready\n    if (oldMethods.length &&\n            EJSON.stringify(oldMethods[0]) !== EJSON.stringify(newMethods[0])) {\n      // Flush the in memory / queue methods\n      _flushInMemoryMethods();\n      // We reset the oldMethods array of outstanding methods\n      oldMethods = [];\n    }\n    // Iterate over the new methods, old ones should be ordered in beginning of\n    // newMethods we do a simple test an throw an error if thats not the case\n    for (var i=0; i < newMethods.length; i++) {\n\n      if (i < oldMethods.length) {\n        // Do a hard slow test to make sure all is in sync\n        if (EJSON.stringify(oldMethods[i]) !== EJSON.stringify(newMethods[i])) {\n          // The client data is corrupted, throw error or force the client to\n          // reload, does not make sense to continue?\n          throw new Error('The method database is corrupted or out of sync at position: ' + i);\n        }\n      } else {\n        // Ok out of oldMethods this is a new method call\n        result.push(newMethods[i]);\n\n        Ground.emit('methodcall', newMethods[i]);\n      }\n    } // EO for iteration\n\n  } else {\n    // If new methods are empty this means that the other client / tap has\n    // Allready sendt and recieved the method calls - so we flush our in mem\n    // Flush the in memory / queue methods\n    _flushInMemoryMethods();\n  }\n\n  // return the result\n  return result;\n};\n\n///////////////////////////// LOAD & SAVE METHODS //////////////////////////////\n// Create the storage for methods\nvar _methodsStorage = Store.create({\n  name: '_methods_',\n  version: 1.1\n});\n\nvar _sendMethod = function _sendMethod(method, connection) {\n  // Send a log message first to the test\n  test.log('SEND', JSON.stringify(method));\n\n  if (test.isMain) {\n    console.warn('Main test should not send methods...');\n  }\n\n  connection.apply(\n    method.method, method.args, method.options, function resumeMethodCallback(err, result) {\n      // We cant fix the missing callbacks made at runtime the\n      // last time the app ran. But we can emit data\n\n      if (err) {\n        test.log('RETURNED ERROR', JSON.stringify(method), err.message);\n      } else {\n        test.log('RETURNED METHOD', JSON.stringify(method));\n      }\n\n      // Emit the data we got back here\n      Ground.emit('method', { method: method, error: err, result: result });\n    }\n  );\n};\n\nvar waitingMethods = [];\n\n// We may end in a situation where things have changed eg. if collections are\n// renamed or left out in the app. We make sure that ground db will try 5 time\n// times and then have the missing methods die.\n// The correct thing in the future would prop. be to have the conflict resolution\n// create patch calls instead of resume.\nvar resumeAttemptsLeft = 5;\n\nvar resumeWaitingMethods = function resumeWaitingMethods() {\n  var missing = [];\n\n  resumeAttemptsLeft--;\n\n  // Resume each method\n  _groundUtil.each(waitingMethods, function eachWaitingMethods(method) {\n    if (method) {\n\n      // name helper for the method\n      var name = method.method;\n\n      if (name) {\n\n        test.log('RESUME', 'Load method \"' + name + '\"');\n        // Get the connection from the allow method resume\n        var methodConnection = _allowMethodResumeMap[name];\n        // Run it in fenced mode since the changes have already been applied\n        // locally\n        if (methodConnection) {\n\n          _groundUtil.connection.stubFence(name, function runFencedMethod() {\n            // Add method to connection\n            _sendMethod(method, methodConnection);\n          });\n\n        } else {\n          // XXX: make sure we keep order\n          // TODO: Check if we should use push or unshift\n          missing.push(method);\n          test.log('RESUME', 'Missing method \"' + name + '\" - retry later');\n          console.warn('Ground method resume: Cannot resume \"' + name + '\" connection not rigged yet, retry later');\n        }\n\n      }\n\n    }\n  });\n\n  // Keep track of missing methods\n  waitingMethods = missing;\n\n  // If no waiting methods - then we must be done?\n  if (!_methodsResumed && !waitingMethods.length || !resumeAttemptsLeft) {\n    // Methods have resumed\n    _methodsResumed = true;\n    _methodsResumedDeps.changed();\n  }\n\n};\n\n\nvar loadMissingMethods = function loadMissingMethods(callback) {\n  _methodsStorage.getItem('methods', function storageLoadMissingMethods(err, data) {\n    test.log('RESUME', 'methods loaded into memory');\n    if (err) {\n      // XXX:\n      callback(err);\n    } else if (data) {\n      // Maxify the data from storage\n      // We are only going to submit the diff\n      // Set missing methods\n      waitingMethods = _getMethodUpdates(MiniMaxMethods.maxify(data));\n    }\n\n    callback();\n  });\n};\n\n// load methods from localstorage and resume the methods\nvar _loadMethods = function _loadMethods() {\n\n  loadMissingMethods(function loadMissingMethods(err) {\n    if (err) {\n      test.log('RESUME', 'Could not load missing methods into memory', err);\n    } else {\n\n      // Try to resume missing methods now\n      resumeWaitingMethods();\n\n      // If not all methods are resumed then try until success\n      if (!_methodsResumed) {\n\n        var interval = Meteor.setInterval(function loadMissingMethodsInterval() {\n          // Try to resume missing methods\n          resumeWaitingMethods();\n\n          // If methods are resumed then stop this\n          if (_methodsResumed) {\n            Meteor.clearInterval(interval);\n          }\n        }, 1000);\n\n      }\n\n    }\n  });\n\n}; // EO load methods\n\n// Save the methods into the localstorage\nvar _saveMethods = function _saveMethods() {\n  if (_methodsResumed) {\n\n    // Ok memory is initialized\n    Ground.emit('cache', { type: 'methods' });\n\n    // Save outstanding methods to localstorage\n    var methods = _getMethodsList();\n//test.log('SAVE METHODS', JSON.stringify(methods));\n    _methodsStorage.setItem('methods', MiniMaxMethods.minify(methods), function storage_saveMethods() { // jshint ignore:line\n      // XXX:\n    });\n\n  }\n};\n\n//////////////////////////// STARTUP METHODS RESUME ////////////////////////////\n\nMeteor.startup(function startupMethodResume() {\n  // Wait some not to conflict with accouts login\n  // TODO: Do we have a better way, instead of depending on time should depend\n  // on en event.\n  Meteor.setTimeout(function loadMethods() {\n    test.log('INIT LOAD METHODS');\n    _loadMethods();\n  }, 500);\n});\n\n/////////////////////////// SYNC TABS METHODS DATABSE //////////////////////////\n\nvar syncDatabaseTimeout = new OneTimeout(150);\n\n// Offline client only databases will sync a bit different than normal\n// This function is a bit hard - but it works - optimal solution could be to\n// have virtual method calls it would complicate things\nvar _syncDatabase = function _syncDatabase() {\n  var self = this;\n  // We set a small delay in case of more updates within the wait\n  syncDatabaseTimeout(function syncDatabaseTimeout() {\n//    if (self && (self.offlineDatabase === true || !Meteor.status().connected)) {\n    if (self) {\n      // Add event hook\n      self.collection.emit('sync');\n      Ground.emit('sync', { type: 'database', collection: self.name });\n      // Hard reset database?\n      self.storage.getItem('data', function storageSyncFetch(err, data) {\n        if (err) {\n          //\n          throw err;\n        } else {\n          // Get the data back in size\n          var newDocs = MiniMaxDB.maxify(data) || {};\n\n          self.collection.find().forEach(function storageSyncFetchEach(doc) {\n            // Remove document\n            self._collection.remove(doc._id);\n            // If found in new documents then hard update\n            if (typeof newDocs[doc._id] !== 'undefined') {\n              // Update doc\n              self._collection.insert(newDocs[doc._id]);\n              delete newDocs[doc._id];\n            }\n          });\n\n          _groundUtil.each(newDocs, function storageSyncFetchEachNew(doc) {\n            // insert doc\n            self._collection.insert(doc);\n          });\n\n        }\n      });\n\n    }\n  });\n};\n\nvar syncMethodsTimeout = new OneTimeout(500);\n\n// Syncronize tabs via method calls\nvar _syncMethods = function _syncMethods() {\n  // We are going to into reload, stop all access to localstorage\n  _isReloading = true;\n  // We are not master and the user is working on another tab, we are not in\n  // a hurry to spam the browser with work, plus there are typically acouple\n  // of db access required in most operations, we wait a sec?\n  syncMethodsTimeout(function _syncMethodsTimeout() {\n    // Add event hook\n    Ground.emit('sync', { type: 'methods'Â });\n    // Load the offline data into our memory\n    _groundUtil.each(_groundDatabases, function syncMethodsTimeoutEach(collection, name) {\n      test.log('SYNC DB', name);\n      _loadDatabase.call(collection);\n    });\n    // Resume methods\n    test.log('SYNC METHODS');\n    _loadMethods();\n    // Resume normal writes\n    _isReloading = false;\n  });\n};\n\n/////////////////////// ADD TRIGGERS IN LIVEDATACONNECTION /////////////////////\n\nif (!test.isMain) {\n\n  // Add hooks method hooks\n  // We need to know when methods are added and when they have returned\n\n  var _superApply = _groundUtil.Connection.prototype.apply;\n  var _superOutstandingMethodFinished = _groundUtil.Connection.prototype._outstandingMethodFinished;\n\n  _groundUtil.Connection.prototype.apply = function applyHook(name /* , args, options, callback */) {\n    // Intercept grounded databases\n    if (_allowMethodResumeMap[name]) {\n      test.debug('APPLY', JSON.stringify(_groundUtil.toArray(arguments)));\n    }\n    // Call super\n    var result = _superApply.apply(this, _groundUtil.toArray(arguments));\n    // Save methods\n    if (_allowMethodResumeMap[name]) {\n      _saveMethods();\n    }\n    // return the result\n    return result;\n  };\n\n  _groundUtil.Connection.prototype._outstandingMethodFinished = function _outstandingMethodFinished() {\n      // Call super\n      _superOutstandingMethodFinished.apply(this);\n      // We save current status of methods\n      _saveMethods();\n      // _outstandingMethodFinished dont return anything\n    };\n\n}\n\n/////////////////////// LOAD CHANGES FROM OTHER TABS ///////////////////////////\n\n// The main test mode should not interfere with tab sync\nif (!test.isMain) {\n\n  // Sync Methods if changed\n  _methodsStorage.addListener('storage', function storageEventListener() {\n    // Method calls are delayed a bit for optimization\n    _syncMethods('mehods');\n\n  });\n\n}\n\n////////////////////////// ADD DEPRECATION NOTICE //////////////////////////////\nif (typeof GroundDB === 'undefined') {\n  GroundDB = function deprecatedGroundDB(name, options) {\n    // Deprecation notice\n    console.warn('The GroundDB scope is deprecating!! Use Ground.Collection instead');\n    return new Ground.Collection(name, options);\n  };\n}\n","//////////////////////////////////////////////////////////////////////////////\n// WRAP MONGO COLLECTION API on prototype\n//////////////////////////////////////////////////////////////////////////////\n\n// Why do we need to overwrite the default insert function?\n//\n// We set _id manually if not already set, this is due to the \"optimization\"\n// added in Meteor and the fact that we cant rely on connection or method\n// invocations in grounddb:\n// \"Don't generate the id if we're the client and the 'outermost' call\n//  This optimization saves us passing both the randomSeed and the id\n//  Passing both is redundant.\"\n//  // Mongo->collection.js\n\n// XXX: This is a bit strange - its the only way of making sure the _id is\n// sent to the server. We want the id to the server if we are doing offline\n// resume - grounddb cannot regenerate the invocation callbacks if browser\n// was closed.\n\nvar _super = _groundUtil.Collection.prototype.insert;\n\n// Overwrite insert\n_groundUtil.Collection.prototype.insert = function(/* arguments */) {\n  /*************************************************************************\n   *  This function is overwritten by GroundDB - Sorry! but we need an _id *\n   *************************************************************************/\n\n  // Convert arguments object into real array\n  var args = _.toArray(arguments);\n\n  // Only make sure _id is set if grounddb is mounted\n  if (this.grounddb) {\n    args[0]._id = args[0]._id || this._makeNewID();\n  }\n\n  // Call super\n  return _super.apply(this, args);\n};\n","//////////////////////////////////////////////////////////////////////////////\n// WRAP EVENTEMITTER API on Ground\n//////////////////////////////////////////////////////////////////////////////\n\n// Add a top level event emitter\nGround.eventemitter = new EventEmitter();\n\n// Wrap the Event Emitter Api \"on\"\nGround.on = function(/* arguments */) {\n  Ground.eventemitter.on.apply(Ground.eventemitter, _.toArray(arguments));\n};\n\n// Wrap the Event Emitter Api \"once\"\nGround.once = function(/* arguments */) {\n  Ground.eventemitter.once.apply(Ground.eventemitter, _.toArray(arguments));\n};\n\n// Wrap the Event Emitter Api \"off\"\nGround.off = function(/* arguments */) {\n  Ground.eventemitter.off.apply(Ground.eventemitter, _.toArray(arguments));\n};\n\n// Wrap the Event Emitter Api \"emit\"\nGround.emit = function(/* arguments */) {\n  Ground.eventemitter.emit.apply(Ground.eventemitter, _.toArray(arguments));\n};\n\n\n// Add api helpers\nGround.addListener = Ground.on;\nGround.removeListener = Ground.off;\nGround.removeAllListeners = Ground.off;\n\n// Add jquery like helpers\nGround.one = Ground.once;\nGround.trigger = Ground.emit;\n","//////////////////////////////////////////////////////////////////////////////\n// WRAP EVENTEMITTER API on prototype\n//////////////////////////////////////////////////////////////////////////////\n\n// Wrap the Event Emitter Api \"on\"\n_groundUtil.Collection.prototype.on = function(/* arguments */) {\n  return this.eventemitter.on.apply(this.eventemitter, _.toArray(arguments));\n};\n\n// Wrap the Event Emitter Api \"once\"\n_groundUtil.Collection.prototype.once = function(/* arguments */) {\n  return this.eventemitter.once.apply(this.eventemitter, _.toArray(arguments));\n};\n\n// Wrap the Event Emitter Api \"off\"\n_groundUtil.Collection.prototype.off = function(/* arguments */) {\n  return this.eventemitter.off.apply(this.eventemitter, _.toArray(arguments));\n};\n\n// Wrap the Event Emitter Api \"emit\"\n_groundUtil.Collection.prototype.emit = function(/* arguments */) {\n  return this.eventemitter.emit.apply(this.eventemitter, _.toArray(arguments));\n};\n\n\n// Add api helpers\n_groundUtil.Collection.prototype.addListener = _groundUtil.Collection.prototype.on;\n_groundUtil.Collection.prototype.removeListener = _groundUtil.Collection.prototype.off;\n_groundUtil.Collection.prototype.removeAllListeners = _groundUtil.Collection.prototype.off;\n\n// Add jquery like helpers\n_groundUtil.Collection.prototype.one = _groundUtil.Collection.prototype.once;\n_groundUtil.Collection.prototype.trigger = _groundUtil.Collection.prototype.emit;\n"]}